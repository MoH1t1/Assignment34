{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n\nAssumptions:\nIndependence of observations.\nNormality of data within each group.\nHomogeneity of variances (equal variance across groups).\n                          \nViolations:\nIndependence: If observations are dependent (e.g., repeated measures without proper handling), results may be biased.\nNormality: Skewed data can affect results; transformations or non-parametric tests may be needed.\nHomogeneity of variances: Unequal variances (heteroscedasticity) can lead to incorrect conclusions, corrected by Welch's ANOVA.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q2. What are the three types of ANOVA, and in what situations would each be used?\n\nOne-way ANOVA: Compares means of three or more groups based on one independent variable.\nTwo-way ANOVA: Compares means across two independent variables, testing for main effects and interaction.\nRepeated Measures ANOVA: Used when the same subjects are measured multiple times under different conditions.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n\nVariance is partitioned into:\nTotal Variance (SST): Total variability in the data.\nExplained Variance (SSE): Variability explained by the group differences.\nResidual Variance (SSR): Variability unexplained by the model. Understanding this helps assess how much of the total variability is accounted for by the factors under study.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport numpy as np\n\ndata = {'group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n        'value': [23, 21, 22, 30, 32, 31, 40, 42, 41]}\n\nimport pandas as pd\ndf = pd.DataFrame(data)\nmodel = ols('value ~ C(group)', data=df).fit()\nanova_table = sm.stats.anova_lm(model)\nprint(anova_table)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "           df  sum_sq  mean_sq      F    PR(>F)\nC(group)  2.0   542.0    271.0  271.0  0.000001\nResidual  6.0     6.0      1.0    NaN       NaN\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\ndf = pd.DataFrame({\n    'factor1': ['A', 'A', 'B', 'B'],\n    'factor2': ['X', 'Y', 'X', 'Y'],\n    'value': [23, 22, 30, 31]\n})\n\nmodel = ols('value ~ C(factor1) + C(factor2) + C(factor1):C(factor2)', data=df).fit()\nanova_table = sm.stats.anova_lm(model)\nprint(anova_table)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                        df        sum_sq       mean_sq    F  PR(>F)\nC(factor1)             1.0  6.400000e+01  6.400000e+01  0.0     NaN\nC(factor2)             1.0  1.262177e-29  1.262177e-29  0.0     NaN\nC(factor1):C(factor2)  1.0  1.000000e+00  1.000000e+00  0.0     NaN\nResidual               0.0  1.729183e-27           inf  NaN     NaN\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n# What can you conclude about the differences between the groups, and how would you interpret these results?\n\nWith an F-statistic of 5.23 and a p-value of 0.02, you can reject the null hypothesis at the 0.05 significance level. This means there are statistically significant differences between the group means. Further post-hoc tests are needed to identify which specific groups differ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n\nMethods for handling Missing Data in Repeated Measures ANOVA:\n  Listwise deletion: Removes any rows with missing data.\n  Imputation: Fills missing values based on other data.\n    \nConsequences: Deletion can reduce sample size, while imputation can introduce bias if not done carefully.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n\nCommon Post-hoc Tests:\nTukeyâ€™s HSD: Used when you want to compare all group pairs after a significant ANOVA.\nBonferroni: A more conservative test for pairwise comparisons, controlling the family-wise error rate.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of \n# the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. \n# Report the F-statistic and p-value, and interpret the results.\n\n# One-Way ANOVA for Diets: Using Python's scipy.stats.f_oneway function:\nfrom scipy import stats\ndiet_A = [5, 6, 7, 4, 6]\ndiet_B = [6, 7, 6, 5, 8]\ndiet_C = [8, 9, 7, 8, 9]\nF_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\nprint(F_statistic, p_value)\n\n# Interpret based on the p-value (if <0.05, there is a significant difference).",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "8.060606060606064 0.006037863050699394\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: \n# Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. \n# Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level\n# (novice vs. experienced). Report the F-statistics and p-values, and interpret the results.\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\ndf = pd.DataFrame({\n    'software': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'experience': ['novice', 'experienced', 'novice', 'experienced', 'novice', 'experienced'],\n    'time': [30, 25, 40, 35, 50, 45]\n})\n\nmodel = ols('time ~ C(software) + C(experience) + C(software):C(experience)', data=df).fit()\nanova_table = sm.stats.anova_lm(model)\nprint(anova_table)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                            df        sum_sq       mean_sq    F  PR(>F)\nC(software)                2.0  4.000000e+02  2.000000e+02  0.0     NaN\nC(experience)              1.0  3.750000e+01  3.750000e+01  0.0     NaN\nC(software):C(experience)  2.0  2.303474e-28  1.151737e-28  0.0     NaN\nResidual                   0.0  1.968997e-27           inf  NaN     NaN\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the \n# control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n# two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, \n# follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n\n# Two-Sample t-test: Using Python's scipy.stats.ttest_ind:\n\nfrom scipy import stats\ncontrol_group = [80, 85, 90, 88, 82]\nexperimental_group = [85, 90, 95, 93, 91]\nt_stat, p_value = stats.ttest_ind(control_group, experimental_group)\nprint(t_stat, p_value)\n\n# If significant (p < 0.05), post-hoc tests can be used to check differences between groups.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\n# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C.\n# They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n# significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other.\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\ndf = pd.DataFrame({\n    'store': ['A', 'B', 'C', 'A', 'B', 'C'],\n    'sales': [300, 250, 400, 320, 270, 410]\n})\n\nmodel = ols('sales ~ C(store)', data=df).fit()\nanova_table = sm.stats.anova_lm(model)\nprint(anova_table)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "           df   sum_sq  mean_sq          F    PR(>F)\nC(store)  2.0  21700.0  10850.0  72.333333  0.002896\nResidual  3.0    450.0    150.0        NaN       NaN\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}